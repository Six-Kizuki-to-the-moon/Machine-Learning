{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained model\n",
    "We used a pre-trained model because for making faster computation training at recommendation_collab on Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../dataset/integration_to_db/merge_ratings.csv')\n",
    "destination = pd.read_csv('../dataset/destination.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  tf.keras.models.load_model('../API/ml-dev/pretrained_collab_rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model.compile(optimizer=Adam(learning_rate = 0.0005), loss='mean_squared_error') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72/72 [==============================] - 1s 6ms/step - loss: 1.1860 - val_loss: 0.6433\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9981 - val_loss: 0.6150\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0686 - val_loss: 0.5903\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9960 - val_loss: 0.5663\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0306 - val_loss: 0.5451\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9974 - val_loss: 0.5240\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9728 - val_loss: 0.5060\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 0.4902\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9154 - val_loss: 0.4737\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9272 - val_loss: 0.4587\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x= [train.wisata_id, train.user_wisata], \n",
    "                    y= train.wisata_rating, \n",
    "                    validation_data = ([train.wisata_id, train.user_wisata], train.wisata_rating), \n",
    "                    epochs =10,\n",
    "                    callbacks=[early_stopping],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
